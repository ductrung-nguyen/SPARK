package spark

import org.apache.spark._
import org.apache.spark.SparkContext._

class RegressionTree {

    val context = new SparkContext("local", "SparkContext")
    val dataInputURL = "/home/loveallufev/semester_project/input/small_input2"
    var featureSet = new FeatureSet("/home/loveallufev/semester_project/input/tag_small_input2", context)

    val myDataFile = context.textFile(dataInputURL, 1)
    var myDataFile2 = scala.io.Source.fromFile(dataInputURL).getLines

    var data = myDataFile2.map(line => line.split(","))
    
     val temp = FeatureInfo("Test", "0", 0)
    temp.addValue(1.0, 10.0)
    temp.addValue(10.0, 1.0)
    temp.addValue(11.0,8.0)
    temp.addValue(6.0,5.0)
    temp.addValue(6.0,7.0)
    temp.addValue(4.0,20.0)
    temp.addValue(5.0,7.0)
    
    /*
    data.map(line => { processLine(line) })

    data.foreach(processLine)

    featureSet.data.foreach(x => println(x.getBestSplitPoint))
    
   
    
    //featureSet.data.foreach(println)

    def processLine(fields: Array[String]) = {
        var i = 0;
        var yValue = parseDouble(fields(fields.length - 1))
        yValue match {
            case Some(yValueDouble) =>
                fields.map(f => {
                    featureSet.data(i).addValue(f, yValueDouble)
                    i = (i + 1) % featureSet.numberOfFeature
                })
            case None => "Invalid data"
        }
    }

    private def parseDouble(s: String) = try { Some(s.toDouble) } catch { case _ => None }
*/
}