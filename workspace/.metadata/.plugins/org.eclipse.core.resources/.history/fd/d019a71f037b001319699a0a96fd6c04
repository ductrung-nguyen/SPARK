package spark

import org.apache.spark._
import org.apache.spark.SparkContext._

class RegressionTree {

    val context = new SparkContext("local", "SparkContext")
    val dataInputURL = "/home/loveallufev/semester_project/input/small_input2"
    var featureSet = new FeatureSet("/home/loveallufev/semester_project/input/tag_small_input2", context)

    val myDataFile = context.textFile(dataInputURL, 1)
    var myDataFile2 = scala.io.Source.fromFile(dataInputURL).getLines

    var data = myDataFile2.map(line => line.split(","))
    
    
    data.map(line => { processLine(line) })

    data.foreach(processLine)
    val bestSplitPoints = featureSet.data.map(x => x.getBestSplitPoint).dropRight(1)
    
    bestSplitPoints.sort((x,y) => x._3 < y._3)
    println(bestSplitPoints.maxBy(_._3))
    
    
    
    
    
    
    
    

    def processLine(fields: Array[String]) = {
        var i = 0;
        var yValue = parseDouble(fields(fields.length - 1))
        yValue match {
            case Some(yValueDouble) =>
                fields.map(f => {
                    featureSet.data(i).addValue(f, yValueDouble)
                    i = (i + 1) % featureSet.numberOfFeature
                })
            case None => "Invalid data"
        }
    }

    private def parseDouble(s: String) = try { Some(s.toDouble) } catch { case _ => None }
}